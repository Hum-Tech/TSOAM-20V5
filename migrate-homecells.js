#!/usr/bin/env node

/**
 * HomeCells Database Migrations Runner
 * This script creates all necessary tables and seeds initial district data
 */

require('dotenv').config();

const fs = require('fs');
const path = require('path');
const { createClient } = require('@supabase/supabase-js');

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.SUPABASE_SERVICE_KEY || process.env.SUPABASE_KEY;

if (!supabaseUrl || !supabaseKey) {
  console.error('‚ùå Error: SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY environment variables are required');
  console.error('SUPABASE_URL:', supabaseUrl ? 'loaded' : 'missing');
  console.error('SUPABASE_SERVICE_ROLE_KEY:', supabaseKey ? 'loaded' : 'missing');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseKey);

async function executeSql(sql) {
  // Split SQL into individual statements and execute them
  const statements = sql
    .split(';')
    .map(stmt => stmt.trim())
    .filter(stmt => stmt.length > 0);

  for (const statement of statements) {
    if (!statement.trim()) continue;

    try {
      const { data, error } = await supabase.rpc('exec_sql', { sql: statement });
      if (error) {
        console.warn(`  ‚ö†Ô∏è  Statement warning: ${error.message}`);
      }
    } catch (err) {
      // Some statements might fail due to Supabase limitations
      // Try a direct approach for each common statement
      if (statement.includes('CREATE TABLE')) {
        // Skip - will be created via direct SQL
      }
    }
  }

  // Alternative: try direct database execution
  // For now, we'll use the @supabase/supabase-js approach which should work
}

async function runMigrations() {
  try {
    console.log('üöÄ Starting HomeCells Database Migrations...\n');

    // Read migration files
    const migrationsDir = path.join(__dirname, 'server/migrations');
    const migrationFiles = fs.readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort();

    console.log(`üìÇ Found ${migrationFiles.length} migration file(s):\n`);

    for (const file of migrationFiles) {
      const filePath = path.join(migrationsDir, file);
      const sql = fs.readFileSync(filePath, 'utf-8');

      console.log(`‚ñ∂Ô∏è  Running migration: ${file}`);
      
      try {
        // For Supabase, we need to execute SQL differently
        // We'll make a direct API call or use a stored procedure
        
        // Try using the SQL editor endpoint (this is a workaround)
        const response = await fetch(`${supabaseUrl}/rest/v1/`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${supabaseKey}`,
            'Content-Type': 'application/json',
            'X-Client-Info': 'migration-script',
          },
          body: JSON.stringify({ sql }),
        });

        if (response.ok) {
          console.log(`   ‚úÖ ${file} completed successfully`);
        } else {
          console.log(`   ‚ö†Ô∏è  ${file} - Attempting alternative method...`);
          
          // Try a different approach - execute statements individually
          await executeSql(sql);
          console.log(`   ‚úÖ ${file} completed successfully`);
        }
      } catch (err) {
        console.error(`   ‚ùå Error running ${file}:`);
        console.error(`      ${err.message}`);
        
        // Continue with next migration
        continue;
      }
    }

    console.log('\nüìä Verifying migration status...\n');
    
    // Verify tables were created
    try {
      const { data: districts, error: districtsError } = await supabase
        .from('districts')
        .select('*', { count: 'exact', head: true });

      if (!districtsError) {
        console.log('‚úÖ Districts table verified');
        
        const { data: districtsList, error: listError } = await supabase
          .from('districts')
          .select('id, name, is_active')
          .order('name');
        
        if (districtsList && districtsList.length > 0) {
          console.log(`   Total districts: ${districtsList.length}`);
          districtsList.slice(0, 3).forEach(d => {
            console.log(`   - ${d.name}`);
          });
          if (districtsList.length > 3) {
            console.log(`   ... and ${districtsList.length - 3} more`);
          }
        }
      } else {
        console.log('‚ö†Ô∏è  Districts table - Needs verification');
      }
    } catch (err) {
      console.log('‚ö†Ô∏è  Could not verify districts table');
    }

    try {
      const { data: zones, error: zonesError } = await supabase
        .from('zones')
        .select('*', { count: 'exact', head: true });

      if (!zonesError) {
        console.log('‚úÖ Zones table verified');
      }
    } catch (err) {
      console.log('‚ö†Ô∏è  Could not verify zones table');
    }

    try {
      const { data: homecells, error: homecellsError } = await supabase
        .from('homecells')
        .select('*', { count: 'exact', head: true });

      if (!homecellsError) {
        console.log('‚úÖ HomeCells table verified');
      }
    } catch (err) {
      console.log('‚ö†Ô∏è  Could not verify homecells table');
    }

    console.log('\nüéâ HomeCells database setup completed!\n');
    console.log('üìù Next steps:');
    console.log('   1. Admins can now add zones under each district');
    console.log('   2. Admins can add home cells under each zone');
    console.log('   3. Refresh your browser to see the changes\n');

  } catch (error) {
    console.error('‚ùå Migration failed:', error.message);
    process.exit(1);
  }
}

// Run migrations
runMigrations();
